{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177e864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, balanced_accuracy_score, roc_auc_score, classification_report\n",
    "from scipy.stats import loguniform, randint\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a233d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(dataset_id=1590, download_data=True, download_qualities=True, download_features_meta_data=True)\n",
    "X, y, categorical_mask, colname=dataset.get_data(target=dataset.default_target_attribute , dataset_format=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64352d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3557343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2         >50K\n",
       "3         >50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "48837    <=50K\n",
       "48838     >50K\n",
       "48839    <=50K\n",
       "48840    <=50K\n",
       "48841     >50K\n",
       "Name: class, Length: 48842, dtype: category\n",
       "Categories (2, object): ['>50K' < '<=50K']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = y.nunique()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fb1a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], shape=(48842,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ecn= LabelEncoder()\n",
    "y = label_ecn.fit_transform(y=y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052a1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1799df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.columns[categorical_mask].tolist()\n",
    "numeric_cols =[]\n",
    "for i, col in enumerate(colname):\n",
    "    if not categorical_mask[i]:\n",
    "        numeric_cols.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a060aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7bb23f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans= preprocessor.fit_transform(X=X_train)\n",
    "X_train_trans.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2372d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=5000,\n",
    "            tol=1e-4,\n",
    "            random_state=42,\n",
    "            solver=\"saga\",\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "lr_param_dist = {\n",
    "    \"clf__C\": loguniform(1e-4, 1e2),\n",
    "    \"clf__l1_ratio\": np.linspace(0, 1, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best Logistic Regression params:\n",
      "{'clf__C': np.float64(0.04374364439939081), 'clf__l1_ratio': np.float64(0.75)}\n"
     ]
    }
   ],
   "source": [
    "lr_search = RandomizedSearchCV(\n",
    "    estimator=lr_pipe,\n",
    "    param_distributions=lr_param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=8,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "lr_search.fit(X_train, y_train)\n",
    "\n",
    "best_lr = lr_search.best_estimator_\n",
    "\n",
    "print(\"Best Logistic Regression params:\")\n",
    "print(lr_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7577fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "            n_jobs=8,\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_param_dist = {\n",
    "    \"clf__n_estimators\": randint(300, 600),\n",
    "    \"clf__max_depth\": [None, 10 ,20, 30],\n",
    "    \"clf__min_samples_split\": randint(2, 20),\n",
    "    \"clf__min_samples_leaf\": randint(1, 10),\n",
    "    \"clf__max_features\": [\"sqrt\", \"log2\", None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace43581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Random Forest params:\n",
      "{'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 7, 'clf__min_samples_split': 19, 'clf__n_estimators': 388}\n"
     ]
    }
   ],
   "source": [
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_pipe,\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = rf_search.best_estimator_\n",
    "\n",
    "print(\"Best Random Forest params:\")\n",
    "print(rf_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970b1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_IG(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.LazyLinear(hidden_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 16)\n",
    "        self.out = nn.Linear(16, output_dim)\n",
    "\n",
    "        # # better initialization for IG smoothness\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) and not isinstance(m, nn.LazyLinear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        logits = self.out(x)  # no softmax\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539629c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    module=MLP_IG,\n",
    "    module__output_dim=n_classes,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    max_epochs=100,\n",
    "    batch_size=64,\n",
    "    iterator_train__shuffle=True,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=0,\n",
    "    callbacks=[EarlyStopping(patience=10)],\n",
    ")\n",
    "\n",
    "# to resolve conflict error between the the preprocesser type output float64 and the \n",
    "# skorch converts NumPy to Torch without dtype casting, and the MLP weights are are float32\n",
    "# creating a conflit\n",
    "to_float32 = FunctionTransformer(\n",
    "    lambda X: X.astype(np.float32),\n",
    "    accept_sparse=True\n",
    ")\n",
    "\n",
    "mlp_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"to_float32\", to_float32),\n",
    "        (\"clf\", net)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "mlp_param_dist = {\n",
    "    \"clf__lr\": loguniform(1e-4, 1e-2),\n",
    "    \"clf__max_epochs\": [50, 100, 150],\n",
    "    \"clf__batch_size\": [32, 64, 128],\n",
    "    \"clf__optimizer__weight_decay\": loguniform(1e-6, 1e-3),\n",
    "    \"clf__optimizer__betas\": [(0.9, 0.999), (0.9, 0.99)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49356a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best MLP params:\n",
      "{'clf__batch_size': 64, 'clf__lr': np.float64(0.0013658426050382536), 'clf__max_epochs': 50, 'clf__optimizer__betas': (0.9, 0.999), 'clf__optimizer__weight_decay': np.float64(0.00033639871159587913)}\n"
     ]
    }
   ],
   "source": [
    "mlp_search = RandomizedSearchCV(\n",
    "    estimator=mlp_pipe,\n",
    "    param_distributions=mlp_param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "mlp_search.fit(X_train, y_train)\n",
    "\n",
    "best_mlp = mlp_search.best_estimator_\n",
    "\n",
    "print(\"Best MLP params:\")\n",
    "print(mlp_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab02536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87      9354\n",
      "           1       0.57      0.85      0.69      2857\n",
      "\n",
      "    accuracy                           0.82     12211\n",
      "   macro avg       0.76      0.83      0.78     12211\n",
      "weighted avg       0.86      0.82      0.83     12211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = best_lr.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6cfbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87      9354\n",
      "           1       0.58      0.87      0.70      2857\n",
      "\n",
      "    accuracy                           0.82     12211\n",
      "   macro avg       0.77      0.84      0.79     12211\n",
      "weighted avg       0.87      0.82      0.83     12211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = best_rf.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075e2a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      9354\n",
      "           1       0.74      0.63      0.68      2857\n",
      "\n",
      "    accuracy                           0.86     12211\n",
      "   macro avg       0.81      0.78      0.79     12211\n",
      "weighted avg       0.85      0.86      0.86     12211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = best_mlp.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
